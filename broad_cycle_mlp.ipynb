{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM9tPCNJ5GMIC5OpEOjfr8k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sb2539/AI-study/blob/master/broad_cycle_mlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yG3S1cf13wjk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm"
      ],
      "metadata": {
        "id": "Gl2G3LMx3-nB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cebe6afe-ddf4-4896-c01b-41c30a304419"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting timm\n",
            "  Downloading timm-0.6.7-py3-none-any.whl (509 kB)\n",
            "\u001b[K     |████████████████████████████████| 509 kB 21.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.13.1+cu113)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (4.1.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2022.6.15)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.6.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from timm.data import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
        "from timm.models.layers import DropPath, trunc_normal_\n",
        "from timm.models.registry import register_model\n",
        "from timm.models.layers.helpers import to_2tuple\n",
        "\n",
        "import math\n",
        "from torch import Tensor\n",
        "from torch.nn import init\n",
        "from torch.nn.modules.utils import _pair\n",
        "from torchvision.ops.deform_conv import deform_conv2d as deform_conv2d_tv"
      ],
      "metadata": {
        "id": "-DiLW8Pc4JBj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Mlp(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):\n",
        "        super().__init__()\n",
        "        out_features = out_features or in_features\n",
        "        hidden_features = hidden_features or in_features\n",
        "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
        "        self.act = act_layer()\n",
        "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
        "        self.drop = nn.Dropout(drop)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.drop(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "G8iswrAJ4Kbi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CycleFC(nn.Module):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels: int,\n",
        "        out_channels: int,\n",
        "        kernel_size,  # re-defined kernel_size, represent the spatial area of staircase FC\n",
        "        stride: int = 1,\n",
        "        padding: int = 0,\n",
        "        dilation: int = 1,\n",
        "        groups: int = 1,\n",
        "        bias: bool = True,\n",
        "    ):\n",
        "        super(CycleFC, self).__init__()\n",
        "\n",
        "        if in_channels % groups != 0:\n",
        "            raise ValueError('in_channels must be divisible by groups')\n",
        "        if out_channels % groups != 0:\n",
        "            raise ValueError('out_channels must be divisible by groups')\n",
        "        if stride != 1:\n",
        "            raise ValueError('stride must be 1')\n",
        "        if padding != 0:\n",
        "            raise ValueError('padding must be 0')\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = _pair(stride)\n",
        "        self.padding = _pair(padding)\n",
        "        self.dilation = _pair(dilation)\n",
        "        self.groups = groups\n",
        "\n",
        "        self.weight = nn.Parameter(torch.empty(out_channels, in_channels // groups, 1, 1))  \n",
        "\n",
        "        if bias:\n",
        "            self.bias = nn.Parameter(torch.empty(out_channels))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "        self.register_buffer('offset', self.gen_offset())\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self) -> None:\n",
        "        init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
        "\n",
        "        if self.bias is not None:\n",
        "            fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight)\n",
        "            bound = 1 / math.sqrt(fan_in)\n",
        "            init.uniform_(self.bias, -bound, bound)\n",
        "\n",
        "    def gen_offset(self):\n",
        "        \"\"\"\n",
        "        offset (Tensor[batch_size, 2 * offset_groups * kernel_height * kernel_width,\n",
        "            out_height, out_width]): offsets to be applied for each position in the\n",
        "            convolution kernel.\n",
        "        \"\"\"\n",
        "        offset = torch.empty(1, self.in_channels*2, 1, 1)\n",
        "        start_idx = (self.kernel_size[0] * self.kernel_size[1]) // 2\n",
        "        assert self.kernel_size[0] == 1 or self.kernel_size[1] == 1, self.kernel_size\n",
        "        for i in range(self.in_channels):\n",
        "            if self.kernel_size[0] == 1:\n",
        "                offset[0, 2 * i + 0, 0, 0] = 0\n",
        "                offset[0, 2 * i + 1, 0, 0] = (i + start_idx) % self.kernel_size[1] - (self.kernel_size[1] // 2)\n",
        "            else:\n",
        "                offset[0, 2 * i + 0, 0, 0] = (i + start_idx) % self.kernel_size[0] - (self.kernel_size[0] // 2)\n",
        "                offset[0, 2 * i + 1, 0, 0] = 0\n",
        "        return offset\n",
        "\n",
        "    def forward(self, input: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            input (Tensor[batch_size, in_channels, in_height, in_width]): input tensor\n",
        "        \"\"\"\n",
        "        B, C, H, W = input.size()\n",
        "        print(\"input size\",input.size())\n",
        "        return deform_conv2d_tv(input, self.offset.expand(B, -1, H, W), self.weight, self.bias, stride=self.stride,\n",
        "                                padding=self.padding, dilation=self.dilation)\n",
        "    def extra_repr(self) -> str:\n",
        "        s = self.__class__.__name__ + '('\n",
        "        s += '{in_channels}'\n",
        "        s += ', {out_channels}'\n",
        "        s += ', kernel_size={kernel_size}'\n",
        "        s += ', stride={stride}'\n",
        "        s += ', padding={padding}' if self.padding != (0, 0) else ''\n",
        "        s += ', dilation={dilation}' if self.dilation != (1, 1) else ''\n",
        "        s += ', groups={groups}' if self.groups != 1 else ''\n",
        "        s += ', bias=False' if self.bias is None else ''\n",
        "        s += ')'\n",
        "        return s.format(**self.__dict__)"
      ],
      "metadata": {
        "id": "V0iZP3uW4bOh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CycleMLP(nn.Module):\n",
        "    def __init__(self, dim, qkv_bias=False, qk_scale=None, attn_drop=0., proj_drop=0.):\n",
        "        super().__init__()\n",
        "        self.mlp_c = nn.Linear(dim, dim, bias=qkv_bias)\n",
        "\n",
        "        self.sfc_h = CycleFC(dim, dim, (1, 3), 1, 0)\n",
        "        self.sfc_w = CycleFC(dim, dim, (3, 1), 1, 0)\n",
        "\n",
        "        self.reweight = Mlp(dim, dim // 4, dim * 3)\n",
        "\n",
        "        self.proj = nn.Linear(dim, dim)\n",
        "        self.proj_drop = nn.Dropout(proj_drop)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, H, W, C = x.shape\n",
        "        h = self.sfc_h(x.permute(0, 3, 1, 2)).permute(0, 2, 3, 1)\n",
        "        w = self.sfc_w(x.permute(0, 3, 1, 2)).permute(0, 2, 3, 1)\n",
        "        c = self.mlp_c(x)\n",
        "        a = (h + w + c).permute(0, 3, 1, 2).flatten(2).mean(2)\n",
        "        a = self.reweight(a).reshape(B, C, 3).permute(2, 0, 1).softmax(dim=0).unsqueeze(2).unsqueeze(2)\n",
        "\n",
        "        x = h * a[0] + w * a[1] + c * a[2]\n",
        "\n",
        "        x = self.proj(x)\n",
        "        x = self.proj_drop(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "NWUVrdmH9Gou"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CycleBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, dim, mlp_ratio=4., qkv_bias=False, qk_scale=None, drop=0., attn_drop=0.,\n",
        "                 drop_path=0., act_layer=nn.GELU, norm_layer=nn.LayerNorm, skip_lam=1.0, mlp_fn=CycleMLP):\n",
        "        super().__init__()\n",
        "        self.norm1 = norm_layer(dim)\n",
        "        self.attn = mlp_fn(dim, qkv_bias=qkv_bias, qk_scale=None, attn_drop=attn_drop)\n",
        "\n",
        "        # NOTE: drop path for stochastic depth, we shall see if this is better than dropout here\n",
        "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
        "\n",
        "        self.norm2 = norm_layer(dim)\n",
        "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
        "        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer)\n",
        "        self.skip_lam = skip_lam\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.drop_path(self.attn(self.norm1(x))) / self.skip_lam\n",
        "        x = x + self.drop_path(self.mlp(self.norm2(x))) / self.skip_lam\n",
        "        return x"
      ],
      "metadata": {
        "id": "6UvDPshl9KVK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchEmbedOverlapping(nn.Module):\n",
        "    \"\"\" 2D Image to Patch Embedding with overlapping\n",
        "    \"\"\"\n",
        "    def __init__(self, patch_size=16, stride=16, padding=0, in_chans=3, embed_dim=768, norm_layer=None, groups=1):\n",
        "        super().__init__()\n",
        "        patch_size = to_2tuple(patch_size)\n",
        "        stride = to_2tuple(stride)\n",
        "        padding = to_2tuple(padding)\n",
        "        self.patch_size = patch_size\n",
        "        # remove image_size in model init to support dynamic image size\n",
        "\n",
        "        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=stride, padding=padding, groups=groups)\n",
        "        self.norm = norm_layer(embed_dim) if norm_layer else nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.proj(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "tK-v_Ouc9MP_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Downsample(nn.Module):\n",
        "    \"\"\" Downsample transition stage\n",
        "    \"\"\"\n",
        "    def __init__(self, in_embed_dim, out_embed_dim, patch_size):\n",
        "        super().__init__()\n",
        "        assert patch_size == 2, patch_size\n",
        "        self.proj = nn.Conv2d(in_embed_dim, out_embed_dim, kernel_size=(3, 3), stride=(2, 2), padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 3, 1, 2)\n",
        "        x = self.proj(x)  # B, C, H, W\n",
        "        x = x.permute(0, 2, 3, 1)\n",
        "        return x"
      ],
      "metadata": {
        "id": "oLCmgnzu9ODG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def basic_blocks(dim, index, layers, mlp_ratio=3., qkv_bias=False, qk_scale=None, attn_drop=0.,\n",
        "                 drop_path_rate=0., skip_lam=1.0, mlp_fn=CycleMLP, **kwargs):\n",
        "    blocks = []\n",
        "\n",
        "    for block_idx in range(layers[index]):\n",
        "        block_dpr = drop_path_rate * (block_idx + sum(layers[:index])) / (sum(layers) - 1)\n",
        "        blocks.append(CycleBlock(dim, mlp_ratio=mlp_ratio, qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
        "                      attn_drop=attn_drop, drop_path=block_dpr, skip_lam=skip_lam, mlp_fn=mlp_fn))\n",
        "    blocks = nn.Sequential(*blocks)\n",
        "\n",
        "    return blocks"
      ],
      "metadata": {
        "id": "pz8MDAnD9PuH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FactorizedReduce(nn.Module):\n",
        "\n",
        "  def __init__(self, C_in, C_out, affine=True):\n",
        "    super(FactorizedReduce, self).__init__()\n",
        "    assert C_out % 2 == 0\n",
        "    self.relu = nn.ReLU(inplace=False)\n",
        "    self.conv_1 = nn.Conv2d(C_in, C_out // 2, 1, stride=2, padding=0, bias=False)\n",
        "    self.conv_2 = nn.Conv2d(C_in, C_out // 2, 1, stride=2, padding=0, bias=False) \n",
        "    self.bn = nn.BatchNorm2d(C_out, affine=affine)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.relu(x)\n",
        "    out = torch.cat([self.conv_1(x), self.conv_2(x[:,:,1:,1:])], dim=1)\n",
        "    out = self.bn(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "0WpZZi269ltF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CycleNet(nn.Module):\n",
        "    \"\"\" CycleMLP Network \"\"\"\n",
        "    def __init__(self, layers, img_size=224, patch_size=4, in_chans=3, num_classes=1000,\n",
        "        embed_dims=None, transitions=None, segment_dim=None, mlp_ratios=None, skip_lam=1.0,\n",
        "        qkv_bias=False, qk_scale=None, drop_rate=0., attn_drop_rate=0., drop_path_rate=0.,\n",
        "        norm_layer=nn.LayerNorm, mlp_fn=CycleMLP, fork_feat=False):\n",
        "\n",
        "        super().__init__()\n",
        "        if not fork_feat:\n",
        "            self.num_classes = num_classes\n",
        "        self.fork_feat = fork_feat\n",
        "\n",
        "        self.patch_embed = PatchEmbedOverlapping(patch_size=7, stride=4, padding=2, in_chans=3, embed_dim=embed_dims[0])\n",
        "       # 추가\n",
        "        self.reduction_stage_output = nn.ModuleList()\n",
        "       ###\n",
        "        network = []\n",
        "        for i in range(len(layers)):\n",
        "            stage = basic_blocks(embed_dims[i], i, layers, mlp_ratio=mlp_ratios[i], qkv_bias=qkv_bias,\n",
        "                                 qk_scale=qk_scale, attn_drop=attn_drop_rate, drop_path_rate=drop_path_rate,\n",
        "                                 norm_layer=norm_layer, skip_lam=skip_lam, mlp_fn=mlp_fn)\n",
        "            network.append(stage)\n",
        "            # 추가\n",
        "            if len(network) > 1:\n",
        "                for j in range(len(network)-1):\n",
        "                    reduction_out = FactorizedReduce(embed_dims[j], embed_dims[j])\n",
        "                    self.reduction_stage_output.append(reduction_out)\n",
        "            # \n",
        "            if i >= len(layers) - 1:\n",
        "                break\n",
        "            # 변경이 필요해 보이는 부분 \n",
        "            if transitions[i] or embed_dims[i] != embed_dims[i+1]:\n",
        "                patch_size = 2 if transitions[i] else 1\n",
        "                network.append(Downsample(embed_dims[i], embed_dims[i+1], patch_size))\n",
        "\n",
        "        self.network = nn.ModuleList(network)\n",
        "\n",
        "        if self.fork_feat:\n",
        "            # add a norm layer for each output\n",
        "            self.out_indices = [0, 2, 4, 6]\n",
        "            for i_emb, i_layer in enumerate(self.out_indices):\n",
        "                if i_emb == 0 and os.environ.get('FORK_LAST3', None):\n",
        "                    # TODO: more elegant way\n",
        "                    \"\"\"For RetinaNet, `start_level=1`. The first norm layer will not used.\n",
        "                    cmd: `FORK_LAST3=1 python -m torch.distributed.launch ...`\n",
        "                    \"\"\"\n",
        "                    layer = nn.Identity()\n",
        "                else:\n",
        "                    layer = norm_layer(embed_dims[i_emb])\n",
        "                layer_name = f'norm{i_layer}'\n",
        "                self.add_module(layer_name, layer)\n",
        "        else:\n",
        "            # Classifier head\n",
        "            self.norm = norm_layer(embed_dims[-1])\n",
        "            self.head = nn.Linear(embed_dims[-1], num_classes) if num_classes > 0 else nn.Identity()\n",
        "        self.apply(self.cls_init_weights)\n",
        "\n",
        "    def cls_init_weights(self, m):\n",
        "        if isinstance(m, nn.Linear):\n",
        "            trunc_normal_(m.weight, std=.02)\n",
        "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "        elif isinstance(m, nn.LayerNorm):\n",
        "            nn.init.constant_(m.bias, 0)\n",
        "            nn.init.constant_(m.weight, 1.0)\n",
        "        elif isinstance(m, CycleFC):\n",
        "            trunc_normal_(m.weight, std=.02)\n",
        "            nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    #def init_weights(self, pretrained=None):\n",
        "     #   \"\"\" mmseg or mmdet `init_weight` \"\"\"\n",
        "      #  if isinstance(pretrained, str):\n",
        "       #     logger = get_root_logger()\n",
        "        #    load_checkpoint(self, pretrained, map_location='cpu', strict=False, logger=logger)\n",
        "\n",
        "    def get_classifier(self):\n",
        "        return self.head\n",
        "\n",
        "    def reset_classifier(self, num_classes, global_pool=''):\n",
        "        self.num_classes = num_classes\n",
        "        self.head = nn.Linear(self.embed_dim, num_classes) if num_classes > 0 else nn.Identity()\n",
        "\n",
        "    def forward_embeddings(self, x):\n",
        "        x = self.patch_embed(x)\n",
        "        # B,C,H,W-> B,H,W,C\n",
        "        x = x.permute(0, 2, 3, 1)\n",
        "        return x\n",
        "\n",
        "    def forward_tokens(self, x):\n",
        "        outs = []\n",
        "        # 추가된 부분\n",
        "        stage_outputs = []\n",
        "        reduce_time = 0\n",
        "        ####\n",
        "        for idx, block in enumerate(self.network):\n",
        "            x = block(x)\n",
        "            # 추가됐지만 변경이 필요해 보이는 부분\n",
        "            stage_outputs.append(x)\n",
        "            if len(stage_outputs) > 1:\n",
        "                for k in range(len(stage_outputs)-1):\n",
        "                    stage_outputs[k] = self.reduction_stage_output[reduce_time](stage_outputs[k])\n",
        "                    reduce_time += 1\n",
        "            #####\n",
        "            if self.fork_feat and idx in self.out_indices:\n",
        "                norm_layer = getattr(self, f'norm{idx}')\n",
        "                x_out = norm_layer(x)\n",
        "                outs.append(x_out.permute(0, 3, 1, 2).contiguous())\n",
        "        if self.fork_feat:\n",
        "            return outs\n",
        "\n",
        "        B, H, W, C = x.shape\n",
        "        x = x.reshape(B, -1, C)\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.forward_embeddings(x)\n",
        "        # B, H, W, C -> B, N, C\n",
        "        x = self.forward_tokens(x)\n",
        "        if self.fork_feat:\n",
        "            return x\n",
        "\n",
        "        x = self.norm(x)\n",
        "        cls_out = self.head(x.mean(1))\n",
        "        return cls_out"
      ],
      "metadata": {
        "id": "knwiM5Iq9Spa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CycleMLP_B5(pretrained=False, **kwargs):\n",
        "    transitions = [True, True, True, True]\n",
        "    layers = [3, 4, 24, 3]\n",
        "    mlp_ratios = [4, 4, 4, 4]\n",
        "    embed_dims = [96, 192, 384, 768]\n",
        "    model = CycleNet(layers, embed_dims=embed_dims, patch_size=7, transitions=transitions,\n",
        "                     mlp_ratios=mlp_ratios, mlp_fn=CycleMLP, **kwargs)\n",
        "    model.default_cfg = default_cfgs['cycle_L']\n",
        "    return model"
      ],
      "metadata": {
        "id": "8IG1xC9f9Yor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    from torchsummary import summary\n",
        "    import pdb\n",
        "\n",
        "    transitions = [True, True, True, True]\n",
        "    layers = [3, 4, 24, 3]\n",
        "    mlp_ratios = [4, 4, 4, 4]\n",
        "    embed_dims = [96, 192, 384, 768]\n",
        "    model = CycleNet(layers, embed_dims=embed_dims, patch_size=7, transitions=transitions,\n",
        "                     mlp_ratios=mlp_ratios, mlp_fn=CycleMLP)\n",
        "    summary(model, (3,224,224), device = 'cpu')"
      ],
      "metadata": {
        "id": "x5SOWoXUHgDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "id": "InoyGuVwPbnm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd967336-bdb3-4e21-fadf-0ee0a0eee01d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CycleNet(\n",
            "  (patch_embed): PatchEmbedOverlapping(\n",
            "    (proj): Conv2d(3, 96, kernel_size=(7, 7), stride=(4, 4), padding=(2, 2))\n",
            "    (norm): Identity()\n",
            "  )\n",
            "  (network): ModuleList(\n",
            "    (0): Sequential(\n",
            "      (0): CycleBlock(\n",
            "        (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): CycleMLP(\n",
            "          (mlp_c): Linear(in_features=96, out_features=96, bias=False)\n",
            "          (sfc_h): CycleFC(CycleFC(96, 96, kernel_size=(1, 3), stride=(1, 1)))\n",
            "          (sfc_w): CycleFC(CycleFC(96, 96, kernel_size=(3, 1), stride=(1, 1)))\n",
            "          (reweight): Mlp(\n",
            "            (fc1): Linear(in_features=96, out_features=24, bias=True)\n",
            "            (act): GELU(approximate=none)\n",
            "            (fc2): Linear(in_features=24, out_features=288, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (proj): Linear(in_features=96, out_features=96, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "        (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
            "          (act): GELU(approximate=none)\n",
            "          (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
            "          (drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (1): CycleBlock(\n",
            "        (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): CycleMLP(\n",
            "          (mlp_c): Linear(in_features=96, out_features=96, bias=False)\n",
            "          (sfc_h): CycleFC(CycleFC(96, 96, kernel_size=(1, 3), stride=(1, 1)))\n",
            "          (sfc_w): CycleFC(CycleFC(96, 96, kernel_size=(3, 1), stride=(1, 1)))\n",
            "          (reweight): Mlp(\n",
            "            (fc1): Linear(in_features=96, out_features=24, bias=True)\n",
            "            (act): GELU(approximate=none)\n",
            "            (fc2): Linear(in_features=24, out_features=288, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (proj): Linear(in_features=96, out_features=96, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "        (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
            "          (act): GELU(approximate=none)\n",
            "          (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
            "          (drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (2): CycleBlock(\n",
            "        (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): CycleMLP(\n",
            "          (mlp_c): Linear(in_features=96, out_features=96, bias=False)\n",
            "          (sfc_h): CycleFC(CycleFC(96, 96, kernel_size=(1, 3), stride=(1, 1)))\n",
            "          (sfc_w): CycleFC(CycleFC(96, 96, kernel_size=(3, 1), stride=(1, 1)))\n",
            "          (reweight): Mlp(\n",
            "            (fc1): Linear(in_features=96, out_features=24, bias=True)\n",
            "            (act): GELU(approximate=none)\n",
            "            (fc2): Linear(in_features=24, out_features=288, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (proj): Linear(in_features=96, out_features=96, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "        (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
            "          (act): GELU(approximate=none)\n",
            "          (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
            "          (drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (1): Downsample(\n",
            "      (proj): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    )\n",
            "    (2): Sequential(\n",
            "      (0): CycleBlock(\n",
            "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): CycleMLP(\n",
            "          (mlp_c): Linear(in_features=192, out_features=192, bias=False)\n",
            "          (sfc_h): CycleFC(CycleFC(192, 192, kernel_size=(1, 3), stride=(1, 1)))\n",
            "          (sfc_w): CycleFC(CycleFC(192, 192, kernel_size=(3, 1), stride=(1, 1)))\n",
            "          (reweight): Mlp(\n",
            "            (fc1): Linear(in_features=192, out_features=48, bias=True)\n",
            "            (act): GELU(approximate=none)\n",
            "            (fc2): Linear(in_features=48, out_features=576, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (proj): Linear(in_features=192, out_features=192, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
            "          (act): GELU(approximate=none)\n",
            "          (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
            "          (drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (1): CycleBlock(\n",
            "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): CycleMLP(\n",
            "          (mlp_c): Linear(in_features=192, out_features=192, bias=False)\n",
            "          (sfc_h): CycleFC(CycleFC(192, 192, kernel_size=(1, 3), stride=(1, 1)))\n",
            "          (sfc_w): CycleFC(CycleFC(192, 192, kernel_size=(3, 1), stride=(1, 1)))\n",
            "          (reweight): Mlp(\n",
            "            (fc1): Linear(in_features=192, out_features=48, bias=True)\n",
            "            (act): GELU(approximate=none)\n",
            "            (fc2): Linear(in_features=48, out_features=576, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (proj): Linear(in_features=192, out_features=192, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
            "          (act): GELU(approximate=none)\n",
            "          (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
            "          (drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (2): CycleBlock(\n",
            "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): CycleMLP(\n",
            "          (mlp_c): Linear(in_features=192, out_features=192, bias=False)\n",
            "          (sfc_h): CycleFC(CycleFC(192, 192, kernel_size=(1, 3), stride=(1, 1)))\n",
            "          (sfc_w): CycleFC(CycleFC(192, 192, kernel_size=(3, 1), stride=(1, 1)))\n",
            "          (reweight): Mlp(\n",
            "            (fc1): Linear(in_features=192, out_features=48, bias=True)\n",
            "            (act): GELU(approximate=none)\n",
            "            (fc2): Linear(in_features=48, out_features=576, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (proj): Linear(in_features=192, out_features=192, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
            "          (act): GELU(approximate=none)\n",
            "          (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
            "          (drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (3): CycleBlock(\n",
            "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): CycleMLP(\n",
            "          (mlp_c): Linear(in_features=192, out_features=192, bias=False)\n",
            "          (sfc_h): CycleFC(CycleFC(192, 192, kernel_size=(1, 3), stride=(1, 1)))\n",
            "          (sfc_w): CycleFC(CycleFC(192, 192, kernel_size=(3, 1), stride=(1, 1)))\n",
            "          (reweight): Mlp(\n",
            "            (fc1): Linear(in_features=192, out_features=48, bias=True)\n",
            "            (act): GELU(approximate=none)\n",
            "            (fc2): Linear(in_features=48, out_features=576, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (proj): Linear(in_features=192, out_features=192, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
            "          (act): GELU(approximate=none)\n",
            "          (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
            "          (drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (3): Downsample(\n",
            "      (proj): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    )\n",
            "    (4): Sequential(\n",
            "      (0): CycleBlock(\n",
            "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): CycleMLP(\n",
            "          (mlp_c): Linear(in_features=384, out_features=384, bias=False)\n",
            "          (sfc_h): CycleFC(CycleFC(384, 384, kernel_size=(1, 3), stride=(1, 1)))\n",
            "          (sfc_w): CycleFC(CycleFC(384, 384, kernel_size=(3, 1), stride=(1, 1)))\n",
            "          (reweight): Mlp(\n",
            "            (fc1): Linear(in_features=384, out_features=96, bias=True)\n",
            "            (act): GELU(approximate=none)\n",
            "            (fc2): Linear(in_features=96, out_features=1152, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "          (act): GELU(approximate=none)\n",
            "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "          (drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (1): CycleBlock(\n",
            "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): CycleMLP(\n",
            "          (mlp_c): Linear(in_features=384, out_features=384, bias=False)\n",
            "          (sfc_h): CycleFC(CycleFC(384, 384, kernel_size=(1, 3), stride=(1, 1)))\n",
            "          (sfc_w): CycleFC(CycleFC(384, 384, kernel_size=(3, 1), stride=(1, 1)))\n",
            "          (reweight): Mlp(\n",
            "            (fc1): Linear(in_features=384, out_features=96, bias=True)\n",
            "            (act): GELU(approximate=none)\n",
            "            (fc2): Linear(in_features=96, out_features=1152, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "          (act): GELU(approximate=none)\n",
            "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "          (drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (2): CycleBlock(\n",
            "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): CycleMLP(\n",
            "          (mlp_c): Linear(in_features=384, out_features=384, bias=False)\n",
            "          (sfc_h): CycleFC(CycleFC(384, 384, kernel_size=(1, 3), stride=(1, 1)))\n",
            "          (sfc_w): CycleFC(CycleFC(384, 384, kernel_size=(3, 1), stride=(1, 1)))\n",
            "          (reweight): Mlp(\n",
            "            (fc1): Linear(in_features=384, out_features=96, bias=True)\n",
            "            (act): GELU(approximate=none)\n",
            "            (fc2): Linear(in_features=96, out_features=1152, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "          (act): GELU(approximate=none)\n",
            "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "          (drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (3): CycleBlock(\n",
            "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): CycleMLP(\n",
            "          (mlp_c): Linear(in_features=384, out_features=384, bias=False)\n",
            "          (sfc_h): CycleFC(CycleFC(384, 384, kernel_size=(1, 3), stride=(1, 1)))\n",
            "          (sfc_w): CycleFC(CycleFC(384, 384, kernel_size=(3, 1), stride=(1, 1)))\n",
            "          (reweight): Mlp(\n",
            "            (fc1): Linear(in_features=384, out_features=96, bias=True)\n",
            "            (act): GELU(approximate=none)\n",
            "            (fc2): Linear(in_features=96, out_features=1152, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "          (act): GELU(approximate=none)\n",
            "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "          (drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (4): CycleBlock(\n",
            "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): CycleMLP(\n",
            "          (mlp_c): Linear(in_features=384, out_features=384, bias=False)\n",
            "          (sfc_h): CycleFC(CycleFC(384, 384, kernel_size=(1, 3), stride=(1, 1)))\n",
            "          (sfc_w): CycleFC(CycleFC(384, 384, kernel_size=(3, 1), stride=(1, 1)))\n",
            "          (reweight): Mlp(\n",
            "            (fc1): Linear(in_features=384, out_features=96, bias=True)\n",
            "            (act): GELU(approximate=none)\n",
            "            (fc2): Linear(in_features=96, out_features=1152, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "          (act): GELU(approximate=none)\n",
            "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "          (drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (5): CycleBlock(\n",
            "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): CycleMLP(\n",
            "          (mlp_c): Linear(in_features=384, out_features=384, bias=False)\n",
            "          (sfc_h): CycleFC(CycleFC(384, 384, kernel_size=(1, 3), stride=(1, 1)))\n",
            "          (sfc_w): CycleFC(CycleFC(384, 384, kernel_size=(3, 1), stride=(1, 1)))\n",
            "          (reweight): Mlp(\n",
            "            (fc1): Linear(in_features=384, out_features=96, bias=True)\n",
            "            (act): GELU(approximate=none)\n",
            "            (fc2): Linear(in_features=96, out_features=1152, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "          (act): GELU(approximate=none)\n",
            "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "          (drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (6): CycleBlock(\n",
            "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): CycleMLP(\n",
            "          (mlp_c): Linear(in_features=384, out_features=384, bias=False)\n",
            "          (sfc_h): CycleFC(CycleFC(384, 384, kernel_size=(1, 3), stride=(1, 1)))\n",
            "          (sfc_w): CycleFC(CycleFC(384, 384, kernel_size=(3, 1), stride=(1, 1)))\n",
            "          (reweight): Mlp(\n",
            "            (fc1): Linear(in_features=384, out_features=96, bias=True)\n",
            "            (act): GELU(approximate=none)\n",
            "            (fc2): Linear(in_features=96, out_features=1152, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "          (act): GELU(approximate=none)\n",
            "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "          (drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (7): CycleBlock(\n",
            "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): CycleMLP(\n",
            "          (mlp_c): Linear(in_features=384, out_features=384, bias=False)\n",
            "          (sfc_h): CycleFC(CycleFC(384, 384, kernel_size=(1, 3), stride=(1, 1)))\n",
            "          (sfc_w): CycleFC(CycleFC(384, 384, kernel_size=(3, 1), stride=(1, 1)))\n",
            "          (reweight): Mlp(\n",
            "            (fc1): Linear(in_features=384, out_features=96, bias=True)\n",
            "            (act): GELU(approximate=none)\n",
            "            (fc2): Linear(in_features=96, out_features=1152, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "          (act): GELU(approximate=none)\n",
            "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "          (drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (8): CycleBlock(\n",
            "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): CycleMLP(\n",
            "          (mlp_c): Linear(in_features=384, out_features=384, bias=False)\n",
            "          (sfc_h): CycleFC(CycleFC(384, 384, kernel_size=(1, 3), stride=(1, 1)))\n",
            "          (sfc_w): CycleFC(CycleFC(384, 384, kernel_size=(3, 1), stride=(1, 1)))\n",
            "          (reweight): Mlp(\n",
            "            (fc1): Linear(in_features=384, out_features=96, bias=True)\n",
            "            (act): GELU(approximate=none)\n",
            "            (fc2): Linear(in_features=96, out_features=1152, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "          (act): GELU(approximate=none)\n",
            "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "          (drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (9): CycleBlock(\n",
            "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): CycleMLP(\n",
            "          (mlp_c): Linear(in_features=384, out_features=384, bias=False)\n",
            "          (sfc_h): CycleFC(CycleFC(384, 384, kernel_size=(1, 3), stride=(1, 1)))\n",
            "          (sfc_w): CycleFC(CycleFC(384, 384, kernel_size=(3, 1), stride=(1, 1)))\n",
            "          (reweight): Mlp(\n",
            "            (fc1): Linear(in_features=384, out_features=96, bias=True)\n",
            "            (act): GELU(approximate=none)\n",
            "            (fc2): Linear(in_features=96, out_features=1152, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "          (act): GELU(approximate=none)\n",
            "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "          (drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (10): CycleBlock(\n",
            "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): CycleMLP(\n",
            "          (mlp_c): Linear(in_features=384, out_features=384, bias=False)\n",
            "          (sfc_h): CycleFC(CycleFC(384, 384, kernel_size=(1, 3), stride=(1, 1)))\n",
            "          (sfc_w): CycleFC(CycleFC(384, 384, kernel_size=(3, 1), stride=(1, 1)))\n",
            "          (reweight): Mlp(\n",
            "            (fc1): Linear(in_features=384, out_features=96, bias=True)\n",
            "            (act): GELU(approximate=none)\n",
            "            (fc2): Linear(in_features=96, out_features=1152, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "          (act): GELU(approximate=none)\n",
            "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "          (drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (11): CycleBlock(\n",
            "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): CycleMLP(\n",
            "          (mlp_c): Linear(in_features=384, out_features=384, bias=False)\n",
            "          (sfc_h): CycleFC(CycleFC(384, 384, kernel_size=(1, 3), stride=(1, 1)))\n",
            "          (sfc_w): CycleFC(CycleFC(384, 384, kernel_size=(3, 1), stride=(1, 1)))\n",
            "          (reweight): Mlp(\n",
            "            (fc1): Linear(in_features=384, out_features=96, bias=True)\n",
            "            (act): GELU(approximate=none)\n",
            "            (fc2): Linear(in_features=96, out_features=1152, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "          (act): GELU(approximate=none)\n",
            "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "          (drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (12): CycleBlock(\n",
            "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): CycleMLP(\n",
            "          (mlp_c): Linear(in_features=384, out_features=384, bias=False)\n",
            "          (sfc_h): CycleFC(CycleFC(384, 384, kernel_size=(1, 3), stride=(1, 1)))\n",
            "          (sfc_w): CycleFC(CycleFC(384, 384, kernel_size=(3, 1), stride=(1, 1)))\n",
            "          (reweight): Mlp(\n",
            "            (fc1): Linear(in_features=384, out_features=96, bias=True)\n",
            "            (act): GELU(approximate=none)\n",
            "            (fc2): Linear(in_features=96, out_features=1152, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "          (act): GELU(approximate=none)\n",
            "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "          (drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (13): CycleBlock(\n",
            "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): CycleMLP(\n",
            "          (mlp_c): Linear(in_features=384, out_features=384, bias=False)\n",
            "          (sfc_h): CycleFC(CycleFC(384, 384, kernel_size=(1, 3), stride=(1, 1)))\n",
            "          (sfc_w): CycleFC(CycleFC(384, 384, kernel_size=(3, 1), stride=(1, 1)))\n",
            "          (reweight): Mlp(\n",
            "            (fc1): Linear(in_features=384, out_features=96, bias=True)\n",
            "            (act): GELU(approximate=none)\n",
            "            (fc2): Linear(in_features=96, out_features=1152, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "          (act): GELU(approximate=none)\n",
            "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "          (drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (14): CycleBlock(\n",
            "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): CycleMLP(\n",
            "          (mlp_c): Linear(in_features=384, out_features=384, bias=False)\n",
            "          (sfc_h): CycleFC(CycleFC(384, 384, kernel_size=(1, 3), stride=(1, 1)))\n",
            "          (sfc_w): CycleFC(CycleFC(384, 384, kernel_size=(3, 1), stride=(1, 1)))\n",
            "          (reweight): Mlp(\n",
            "            (fc1): Linear(in_features=384, out_features=96, bias=True)\n",
            "            (act): GELU(approximate=none)\n",
            "            (fc2): Linear(in_features=96, out_features=1152, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "          (act): GELU(approximate=none)\n",
            "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "          (drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (15): CycleBlock(\n",
            "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): CycleMLP(\n",
            "          (mlp_c): Linear(in_features=384, out_features=384, bias=False)\n",
            "          (sfc_h): CycleFC(CycleFC(384, 384, kernel_size=(1, 3), stride=(1, 1)))\n",
            "          (sfc_w): CycleFC(CycleFC(384, 384, kernel_size=(3, 1), stride=(1, 1)))\n",
            "          (reweight): Mlp(\n",
            "            (fc1): Linear(in_features=384, out_features=96, bias=True)\n",
            "            (act): GELU(approximate=none)\n",
            "            (fc2): Linear(in_features=96, out_features=1152, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "          (act): GELU(approximate=none)\n",
            "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "          (drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (16): CycleBlock(\n",
            "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): CycleMLP(\n",
            "          (mlp_c): Linear(in_features=384, out_features=384, bias=False)\n",
            "          (sfc_h): CycleFC(CycleFC(384, 384, kernel_size=(1, 3), stride=(1, 1)))\n",
            "          (sfc_w): CycleFC(CycleFC(384, 384, kernel_size=(3, 1), stride=(1, 1)))\n",
            "          (reweight): Mlp(\n",
            "            (fc1): Linear(in_features=384, out_features=96, bias=True)\n",
            "            (act): GELU(approximate=none)\n",
            "            (fc2): Linear(in_features=96, out_features=1152, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "          (act): GELU(approximate=none)\n",
            "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "          (drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (17): CycleBlock(\n",
            "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): CycleMLP(\n",
            "          (mlp_c): Linear(in_features=384, out_features=384, bias=False)\n",
            "          (sfc_h): CycleFC(CycleFC(384, 384, kernel_size=(1, 3), stride=(1, 1)))\n",
            "          (sfc_w): CycleFC(CycleFC(384, 384, kernel_size=(3, 1), stride=(1, 1)))\n",
            "          (reweight): Mlp(\n",
            "            (fc1): Linear(in_features=384, out_features=96, bias=True)\n",
            "            (act): GELU(approximate=none)\n",
            "            (fc2): Linear(in_features=96, out_features=1152, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "          (act): GELU(approximate=none)\n",
            "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "          (drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (18): CycleBlock(\n",
            "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): CycleMLP(\n",
            "          (mlp_c): Linear(in_features=384, out_features=384, bias=False)\n",
            "          (sfc_h): CycleFC(CycleFC(384, 384, kernel_size=(1, 3), stride=(1, 1)))\n",
            "          (sfc_w): CycleFC(CycleFC(384, 384, kernel_size=(3, 1), stride=(1, 1)))\n",
            "          (reweight): Mlp(\n",
            "            (fc1): Linear(in_features=384, out_features=96, bias=True)\n",
            "            (act): GELU(approximate=none)\n",
            "            (fc2): Linear(in_features=96, out_features=1152, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "          (act): GELU(approximate=none)\n",
            "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "          (drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (19): CycleBlock(\n",
            "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): CycleMLP(\n",
            "          (mlp_c): Linear(in_features=384, out_features=384, bias=False)\n",
            "          (sfc_h): CycleFC(CycleFC(384, 384, kernel_size=(1, 3), stride=(1, 1)))\n",
            "          (sfc_w): CycleFC(CycleFC(384, 384, kernel_size=(3, 1), stride=(1, 1)))\n",
            "          (reweight): Mlp(\n",
            "            (fc1): Linear(in_features=384, out_features=96, bias=True)\n",
            "            (act): GELU(approximate=none)\n",
            "            (fc2): Linear(in_features=96, out_features=1152, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "          (act): GELU(approximate=none)\n",
            "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "          (drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (20): CycleBlock(\n",
            "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): CycleMLP(\n",
            "          (mlp_c): Linear(in_features=384, out_features=384, bias=False)\n",
            "          (sfc_h): CycleFC(CycleFC(384, 384, kernel_size=(1, 3), stride=(1, 1)))\n",
            "          (sfc_w): CycleFC(CycleFC(384, 384, kernel_size=(3, 1), stride=(1, 1)))\n",
            "          (reweight): Mlp(\n",
            "            (fc1): Linear(in_features=384, out_features=96, bias=True)\n",
            "            (act): GELU(approximate=none)\n",
            "            (fc2): Linear(in_features=96, out_features=1152, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "          (act): GELU(approximate=none)\n",
            "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "          (drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (21): CycleBlock(\n",
            "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): CycleMLP(\n",
            "          (mlp_c): Linear(in_features=384, out_features=384, bias=False)\n",
            "          (sfc_h): CycleFC(CycleFC(384, 384, kernel_size=(1, 3), stride=(1, 1)))\n",
            "          (sfc_w): CycleFC(CycleFC(384, 384, kernel_size=(3, 1), stride=(1, 1)))\n",
            "          (reweight): Mlp(\n",
            "            (fc1): Linear(in_features=384, out_features=96, bias=True)\n",
            "            (act): GELU(approximate=none)\n",
            "            (fc2): Linear(in_features=96, out_features=1152, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "          (act): GELU(approximate=none)\n",
            "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "          (drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (22): CycleBlock(\n",
            "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): CycleMLP(\n",
            "          (mlp_c): Linear(in_features=384, out_features=384, bias=False)\n",
            "          (sfc_h): CycleFC(CycleFC(384, 384, kernel_size=(1, 3), stride=(1, 1)))\n",
            "          (sfc_w): CycleFC(CycleFC(384, 384, kernel_size=(3, 1), stride=(1, 1)))\n",
            "          (reweight): Mlp(\n",
            "            (fc1): Linear(in_features=384, out_features=96, bias=True)\n",
            "            (act): GELU(approximate=none)\n",
            "            (fc2): Linear(in_features=96, out_features=1152, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "          (act): GELU(approximate=none)\n",
            "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "          (drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (23): CycleBlock(\n",
            "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): CycleMLP(\n",
            "          (mlp_c): Linear(in_features=384, out_features=384, bias=False)\n",
            "          (sfc_h): CycleFC(CycleFC(384, 384, kernel_size=(1, 3), stride=(1, 1)))\n",
            "          (sfc_w): CycleFC(CycleFC(384, 384, kernel_size=(3, 1), stride=(1, 1)))\n",
            "          (reweight): Mlp(\n",
            "            (fc1): Linear(in_features=384, out_features=96, bias=True)\n",
            "            (act): GELU(approximate=none)\n",
            "            (fc2): Linear(in_features=96, out_features=1152, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "          (act): GELU(approximate=none)\n",
            "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "          (drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (5): Downsample(\n",
            "      (proj): Conv2d(384, 768, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    )\n",
            "    (6): Sequential(\n",
            "      (0): CycleBlock(\n",
            "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): CycleMLP(\n",
            "          (mlp_c): Linear(in_features=768, out_features=768, bias=False)\n",
            "          (sfc_h): CycleFC(CycleFC(768, 768, kernel_size=(1, 3), stride=(1, 1)))\n",
            "          (sfc_w): CycleFC(CycleFC(768, 768, kernel_size=(3, 1), stride=(1, 1)))\n",
            "          (reweight): Mlp(\n",
            "            (fc1): Linear(in_features=768, out_features=192, bias=True)\n",
            "            (act): GELU(approximate=none)\n",
            "            (fc2): Linear(in_features=192, out_features=2304, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (act): GELU(approximate=none)\n",
            "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (1): CycleBlock(\n",
            "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): CycleMLP(\n",
            "          (mlp_c): Linear(in_features=768, out_features=768, bias=False)\n",
            "          (sfc_h): CycleFC(CycleFC(768, 768, kernel_size=(1, 3), stride=(1, 1)))\n",
            "          (sfc_w): CycleFC(CycleFC(768, 768, kernel_size=(3, 1), stride=(1, 1)))\n",
            "          (reweight): Mlp(\n",
            "            (fc1): Linear(in_features=768, out_features=192, bias=True)\n",
            "            (act): GELU(approximate=none)\n",
            "            (fc2): Linear(in_features=192, out_features=2304, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (act): GELU(approximate=none)\n",
            "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (2): CycleBlock(\n",
            "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): CycleMLP(\n",
            "          (mlp_c): Linear(in_features=768, out_features=768, bias=False)\n",
            "          (sfc_h): CycleFC(CycleFC(768, 768, kernel_size=(1, 3), stride=(1, 1)))\n",
            "          (sfc_w): CycleFC(CycleFC(768, 768, kernel_size=(3, 1), stride=(1, 1)))\n",
            "          (reweight): Mlp(\n",
            "            (fc1): Linear(in_features=768, out_features=192, bias=True)\n",
            "            (act): GELU(approximate=none)\n",
            "            (fc2): Linear(in_features=192, out_features=2304, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (act): GELU(approximate=none)\n",
            "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  (head): Linear(in_features=768, out_features=1000, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-model-summary"
      ],
      "metadata": {
        "id": "mjWMNMBRQYhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pytorch_model_summary\n",
        "\n",
        "print(pytorch_model_summary.summary(model, torch.empty(5,3,224,224), show_hierarchical=True))"
      ],
      "metadata": {
        "id": "fRv7sIQOQeUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchviz"
      ],
      "metadata": {
        "id": "JZ9Vq7vzSlui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchviz import make_dot\n",
        "\n",
        "x = torch.zeros(1, 3, 224, 224)\n",
        "make_dot(model(x), params=dict(list(model.named_parameters())))"
      ],
      "metadata": {
        "id": "Le-y1yylR0EC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hiddenlayer"
      ],
      "metadata": {
        "id": "WW144OS-RNZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import hiddenlayer as hl\n",
        "z = torch.zeros(1, 3, 224, 224)\n",
        "transforms = [hl.transforms.Prune('Constant')]\n",
        "graph = hl.build_graph(model, z, transforms = transforms)\n",
        "graph.theme = hl.graph.THEMES['blue'].copy()\n",
        "graph"
      ],
      "metadata": {
        "id": "nZ5ppheNSjnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hl.build_graph(model, z)"
      ],
      "metadata": {
        "id": "XRygHfRSTgrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx-pytorch"
      ],
      "metadata": {
        "id": "tl-yj1nkYhCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_names = ['test']\n",
        "output_names = ['out']\n",
        "\n",
        "at = torch.zeros(1,3,224,224)\n",
        "torch.onnx.export(model, at, 'temp', input_names = input_names, output_names = output_names)"
      ],
      "metadata": {
        "id": "9TCtCHIDY34R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q = torch.empty(1,56,56,96)\n",
        "w = torch.empty(1,56,56,96)\n",
        "e = torch.empty(1,56,56,96)\n",
        "ap = (q + w + e)"
      ],
      "metadata": {
        "id": "kfV-dF57YxPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ap.size()"
      ],
      "metadata": {
        "id": "ZZD0jqgjZCFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aw = ap.permute(0,3,1,2)"
      ],
      "metadata": {
        "id": "XDM8uNzwZEu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aw.size()"
      ],
      "metadata": {
        "id": "w_V_MqrDZKu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ae = aw.flatten(2)"
      ],
      "metadata": {
        "id": "fvQxKJUOZNLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ae.size()"
      ],
      "metadata": {
        "id": "fkGNtXY1ZShL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ar = ae.mean(2)\n",
        "ar.size()"
      ],
      "metadata": {
        "id": "MoHAOU90ZXrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PE1hjDsKc1CU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "az = torch.randn(4, 3)\n",
        "print(az)\n",
        "ch = torch.mean(az, 1)\n",
        "torch.mean(az, 1, True)\n",
        "print(ch)\n",
        "print(ch.size())"
      ],
      "metadata": {
        "id": "qeGTaDu8bMEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qt = torch.empty(3,49,768)\n",
        "print(qt.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOvfp2vF2Wmr",
        "outputId": "c1f467ad-4b8d-45ad-c062-3ad64044facd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 49, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qt.mean(1).size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NgGFKcr2eJC",
        "outputId": "e4196de9-9ea2-4ecc-e546-9cdcba7a1192"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}